\section{Ejercicio 4: Metaheurística}

  % \begin{figure}[ht]
  %   \begin{center}
  %     \includegraphics[width=0.5\columnwidth]{imagenes/pacman.png}
  %     \caption{Perdidos y con poca fuerza}
  %   \end{center}
  % \end{figure}

    % 1. Describir detalladamente el problema a resolver dando ejemplos del mismo y sus soluciones.
    \subsection{Descripción del problema y solución propuesta}
        En este punto, se pidió realizar un algoritmo basado en una metaheurística que resuelva el problema en cuestión. El mismo al tratarse de una metaheurística puede no dar la solución óptima, y puede no devolver una solución aunque la misma exista.

    % 2. Explicar de forma clara, sencilla, estructurada y concisa, las ideas desarrolladas para la resolución del problema. Utilizar pseudocódigo y lenguaje coloquial (no código fuente). Justificar por qué el procedimiento resuelve efectivamente el problema.
        Se decidió utilizar como metaheurística para resolver esta variante del TSP, GRASP. De esta forma se explora el espacio de soluciones, partiendo de diferentes instancias y tratando de mejorarlas mediante búsqueda local. La idea de GRASP es que cada búsqueda va a converger en caso de ser posible a un mínimo local. Como se comienza de distintas instancias se van a explorar varios mínimos locales distintos, con lo cual la solución se puede obtener tomando la mejor de estas buenas soluciones. Como la eficacia de GRASP depende de empezar de soluciones lo suficientemente diferentes utiliza una heurística greedy a la que le suma aleatoridad, en la cual en vez de seleccionar siempre al mejor candidato para una solución, selecciona uno al azar de un grupo de candidatos (el RCL), cuyo tamaño o criterio de selección es configurable. La otra parte configurable de GRASP es la determinación de cuánto se va a buscar, es decir, cuanto tiempo se va a invertir en generar soluciones greedy aleatoria y tratar de mejorarlas. Para este caso particular de este problema, la implementación de GRASP elegida consiste en lo siguiente: se obtiene una solución (en caso de ser posible) mediante una heurística greedy. La misma es similar a la desarrollada en el ejercicio 2. La diferencia es que se le agrega aleatoridad, ya que no se toma a la estación más cercana sino que se eligen k estaciones más cercanas (siendo k un parámetro configurable) y se elige una al azar de esas estaciones. La misma estación elegida tiene que ser factible de ser visitada. En caso contrario, el algoritmo devuelve que no encontró solución. Si se toma como parámetro k = 1, este algoritmo greedy es exactamente igual al desarrollado en el ejercicio 2 ya que en todas las iteraciones va a elegir al más cercano. Si se toma como k la cantidad de estaciones total, el algoritmo se transforma en uno completamente aleatorio ya que en cada iteración se toma cualquiera estación. Luego de obtenerse una solución a la misma se le aplica la búsqueda local desarrollada en el ejercicio 3 para tratar de mejorarla. Este procedimiento se repite varias veces hasta que se cumple la condición de parada (parámetro configurable). Se usaron dos condiciones de parada distintas: una es determinar una cantidad de repeticiones que se desea realizar el procedimiento (condición sobre la cantidad de repeticiones del ciclo) y la otra es una cantidad de repeticiones en la cual no se mejoró una solución (condición sobre la cantidad de repeticiones sin mejorar). En ambos casos siempre el algoritmo termina ya que en el primer caso se fija la cantidad de repeticiones (por lo tanto el ciclo corre un número finito de veces) y en el otro aunque se elija un número muy grande, siempre a partir de un momento la solución no se va a poder mejorar (cuando se encuentra la óptima), por lo que en el peor caso si la óptima es encontrada rápidamente por el algoritmo, se va ejecutar una vez encontrada, la cantidad de iteraciones fijada, ya que no se va a poder encontrar ninguna mejor. En cada paso, se va guardando la solución mejor que se encuentra. Es decir, se mantiene una solución, que se actualiza en caso de que se encuentre una mejor en cada iteración de este procedimiento. Al finalizar se retorna la mejor solución encontrada.

        El algoritmo propuesto es el siguiente:

         \begin{codesnippet}
            \begin{verbatim}
			enum crit = { A, B }
			
solverEj4(vector<Estacion> estaciones, vector<vector<double> > distancias, n, m,
          k, grasp, crit criterioTipo, int criterioCant, bool vecindarioBusqLocal) {
    solucion s1
    solucion s2
    solucion best
    i = 0
    bool mejor
    double nuevaSol

    mientras (i < criterioCant)
        s1 = greedyRandomized(estaciones, distancias, n, m, k, grasp)
        s2 = solucionEj3(s1, estaciones, distancias, k, vecindarioBusqLocal)

        mejor = False
        nuevaSol = s2.first
        si i == 0 || (nuevaSol > -1 && nuevaSol < best.first) 
            best = s2
            si i > 0
                mejor = True
            fin si
        fin si
          

        si criterioTipo == A
            i++
        fin si

        si criterioTipo == B && mejor == False
            i++
        fin si
		
    fin mientras
    
    devolver best
            \end{verbatim}
            \end{codesnippet}


        El algoritmo consiste en un ciclo, el cual se ejecuta mientras no se haya llegado a la condición de terminación. La condición de terminación está dada por una tupla (denominada criterio) que contiene en su primer coordenada un entero, que es el que se usa en la condición del ciclo para saber si hay que cortar o no. La segunda coordenada es un booleano y sirve para identificar cual de los dos criterios que definimos se está utilizando. El booleano si es verdadero indica que se usa el criterio de parar cuando no se pudo mejorar en k veces la solución siendo k el entero de la primera coordenada. Si es falso, significa que se usa el criterio de correr directamente k veces el ciclo, siendo k también el entero de la primer coordenada.
        En el cuerpo del ciclo lo que se realiza es obtener una solución llamando a la función \textit{greedyRandomized}, la cual realiza lo mismo que la implementada en el ejercicio 2, salvo que en vez de seleccionar a la estación más cercana a la que se puede ir en cada paso, selecciona una al azar de n estaciones cercanas, siendo n el entero \textit{grasp} que se le pasa a la función. Luego de eso se aplica búsqueda local, llamando a la función \textit{solucionEj3}, la cual es exactamente la misma que la desarrollada en el ejercicio 3. Si nos encontramos en la primera iteración del ciclo o la solución obtenida es mejor que la anterior que teniamos, entonces se actualiza la nueva mejor solución obtenida con la encontrada en esta iteración.
        Finalmente se pregunta si se está usando el criterio de ejecutar k veces fijo (con lo cual la variable \textit{criterio.second} sería falsa) y en caso de ser así se suma uno al contador del ciclo. Sino, se trata del otro criterio y sólo se actualiza el contador si no se encontró una mejor solución en la iteración (hecho representado por el valor de la variable booleana \textit{mejor}), sumándole 1.
        Una vez terminado el ciclo se devuelve la mejor solución obtenida.

  \subsection{Experimentación}

    Para poder comparar cada configuración posible y obtener de ahí la configuración óptima. Se generaron 30 instancias random, las cuales nos aseguramos que tengan solución. Luego se realizaron dos experimentos. En el primero, se iteró sobre la cantidad de vértices que entran en la RCL. Mientras que en el segundo, se iteró sobre el límite de cada criterio de parada. Para ambos al igual que en el \textbf{Ejercicio 3}, se buscó comparar por un lado, qué configuración devolvía mejores distancias, además de qué configuración corría en menor tiempo. En cada gráfico se usaron las siguientes referencias, P = Criterio de paradas, i = Iteraciones del criterio, V = vecindario de búsqueda local, RCL = K vértices que accederan a la RCL.

\subsubsection{Experimento 1: RCL}

En el siguiente experimento, se crearon 30 instancias random, las mismas tenían, entre 1 y 15 gimnasios. Los mismos requerían entre 0 y 20 pociones. Las posiciones de las estaciones también fueron random. Además, se usaron las 30 instancias con 4 configuraciones distintas. En las 4 configuraciones se modificó por un lado el vecindario utilizado en la Búsqueda Local y el criterio de parada, en el cual la cantidad de iteraciones del criterio se fijó en 15.

De esta manera las siguientes 4 configuraciones son 

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c| } 
 \hline
 Instancias&Busqueda Local&Criterio de parada\\ 
 \hline
 Configuración 0 & Vecindario A & Iterar K veces\\
 \hline
 Configuración 1 & Vecindario A & Iterar hasta K peores\\
 \hline
 Configuración 2 & Vecindario B & Iterar K veces \\
 \hline
 Configuración 3 & Vecindario B & Iterar hasta K peores\\
 \hline
\end{tabular}
\caption{Configuraciones experimento 1}
\end{table}


Luego por cada instancia, con cada configuración, se iteró el K de RCL, de 1 a 15. Por cada K, se corrió 20 veces el mismo algoritmo, y se sacó un promedio del tiempo y de la distancia.
Además se sacó un promedio de la distancia y el tiempo, entre las 30 instancias con la misma configuración y el mismo K. De esta manera se contaba con un solo promedio de tiempo y distancia por cada K, y por cada configuracion.

  \begin{figure}[H]
      \begin{center}
        \includegraphics[width=0.7\columnwidth]{imagenes/Ej4/ej4_exp1_Tiempo.png}
      \end{center}
  \end{figure}


  Luego, a partir de esta experimentación, pudimos observar que a medida que crecía la lista RCL, crecía la cantidad de elementos a randomizar, y esto impactaba directamente en el tiempo de ejecución. En el gráfico esto se observa por el crecimiento del tiempo con respecto al crecimiento del tamaño de la RCL. Por otro lado, pudimos notar que el aspecto fundamental para el tiempo de corrida, fue el vecindario utilizado. Esto se debe a que, como fue mencionado en el \textbf{Ejercicio 3}, debido a que intercambiar gimnasios en los recorridos, genera menos soluciones, pues caer en un recorrido válido intercambiando gimnasios con distintas pociones es muy poco probable. Luego, intercambiar pokeparadas, dado que no puede suceder que caiga en un recorrido inválido, cualquier intercambio puede llegar a ser una posible mejor solución o mínimo local. Finalmente, otro aspecto que impactó directamente en el tiempo de ejecución, fue el criterio de parada. Si bien la diferencia de tiempo es mínima para el vecindario B, dentro del vecindario A se puede observar que en todo momento, el criterio de parada 1 con 15 iteraciones, era aquel que menos tardaba. Concluyendo de esta manera, que en cuanto a tiempos, la configuración más optima, se da con el vecindario B, y con el criterio de parada 1, además de un RCL = 1. La comparación en cuanto a criterios, se da en la sección de \textbf{Experimento 2}.

  \par Un segundo aspecto a comparar es la calidad de solución,

\begin{figure}[H]
    \begin{center}
      \includegraphics[width=0.7\columnwidth]{imagenes/Ej4/ej4_exp1_Distancia.png}
    \end{center}
\end{figure}


Para este entonces, volvemos a notar como el vecindario, es la sección fundamental de la metaheurística, dado que, comparando a partir de los vecindarios, el vecindario A, es aquel que mejor distancia consigue, a diferencia del B, para todo criterio y para todo valor de RCL, nuevamente la justificación de porqué el vecindario A supera al vecindario B, es explicado en el \textbf{Ejercicio 3}. Para poder sacar una mejor conclusión, debemos comparar el vecindario A y el vecindario B independientemente.
Por un lado en el vecindario A, notamos que para un RCL = 2, es donde, para cualquier criterio, consigue la mejor distancia. Esto podría deberse a que, a mayor RCL, las posibilidades de obtener, luego de randomizar la RCL, una próxima estación con una distancia corta, es menor. Mientras que, para un RCL = 1, el algoritmo metaheurístico, pasaría a ser similar a un algoritmo greedy, junto con una búsqueda local. Por otro lado, dentro del vecindario A, no encontramos una mejora lo suficientemente notable, como para decidir acerca de qué criterio de parada, es óptimo junto a él. Por otro lado, el vecindario B, tiene un empeoramiento de calidad de solución a medida que crece el RCL. Esto puede deberse, no tanto a la influencia de la randomización, sino a la búsqueda local, dado que en general, el vecindario B tiene una peor calidad de solución. Al igual que con el vecindario A, no notamos ninguna mejora a partir del criterio de parada. Luego, de este experimento, concluímos que el vecindario A con una RCL = 2, es quien devuelve una mejor solución, sin importar el criterio de parada.


\par Finalmente, la conclusión de este experimento, es que, en principio, no se puede obtener un algoritmo eficiente en cuanto a tiempo y calidad de la solución a la vez si se depende de la RCL. Por otro lado, la fuerte influencia de los vecindarios utilizados en la búsqueda local dentro del algoritmo, tanto para tiempos como para calidad de solución. Es decir, según que sea necesario, el vecindario A devolverá una mejor solución, en más tiempo. Así como el vecindario B, tarda menos y es peor en cuanto a solución. Por otro lado, el tamaño de la RCL, fue el segundo factor de crecimiento, tanto para distancia como para tiempos. En ambas comparaciones, (exceptuando que en RCL = 2, la solución mejoró), tanto el tiempo como la calidad de solución, empeoraban a medida que crecía. Luego se buscará en próximos experimentos, ver cuánto influye el criterio y sus iteraciones.



\subsubsection{Experimento 2: Iterar el límite de los criterios de parada}

Para este segundo experimento, se usaron las mismas instancias, con la diferencia que se fijó el RCL en 5, además de iterar de 1 a 100 el límite de ambos criterios de parada.


\begin{figure}[H]
    \begin{center}
      \includegraphics[width=0.7\columnwidth]{imagenes/Exp2DistanciaEj4.png}
    \end{center}
\end{figure}

\begin{figure}[H]
    \begin{center}
      \includegraphics[width=0.7\columnwidth]{imagenes/Exp2TiempoEj4.png}
    \end{center}
\end{figure}


En primer lugar, en el primer gráfico como fue esperado, a mayor cantidad de iteraciones de criterio de parada, son mayores las soluciones recorridas dentro del campo de solución. Es por esto que es más probable que se encuentren mejores soluciones.

\par Por otro lado, en términos de tiempo, como fue esperado si la cantidad de iteraciones de la metaheurística crece, el tiempo de corrida crece linealmente.

\par Finalmente comparamos ambos criterios de parada cada uno con una vecindad distinta


\begin{figure}[H]
\minipage{0.5\textwidth}
  \includegraphics[width=\linewidth]{imagenes/Exp2Ej2DistanciaCrit1.png}
  \caption{Criterio 1}
\endminipage\hfill
\minipage{0.5\textwidth}%
  \includegraphics[width=\linewidth]{imagenes/Exp2Ej2DistanciaCrit2.png}
  \caption{Criterio 2}
\endminipage
\end{figure}



Se observa que nuevamente, la selección del vecindario es determinante a la hora de una mejor solución.
